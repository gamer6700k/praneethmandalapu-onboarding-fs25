{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUpekJpnJ1K0",
        "outputId": "ca660e84-5dbf-45f0-8ea5-cdb36fbd0dd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- part 1: TENSOR stuff  ---\n",
            "SCALAR:\n",
            "42 (shape: torch.Size([]), dim: 0)\n",
            "vector:\n",
            "tensor([1, 2, 3]) (shape: torch.Size([3]), dim: 1)\n",
            "mATRIx:\n",
            "tensor([[ 5, 10],\n",
            "        [15, 20]]) (shape: torch.Size([2, 2]), dim: 2)\n",
            "3D tensor is just a:\n",
            "tensor([[[1, 2],\n",
            "         [3, 4]]]) (shape: torch.Size([1, 2, 2]), dim: 3)\n",
            "\n",
            "========================================\n",
            "\n",
            "--- part 2: doing MATHS on tensors ---\n",
            "Orig:\n",
            " tensor([1, 2, 3])\n",
            "Add 10: tensor([11, 12, 13])\n",
            "TIMES self: tensor([1, 4, 9])\n",
            "\n",
            "Mat mul A (torch.Size([2, 2])) @ B (torch.Size([2, 2])):\n",
            "tensor([[19, 22],\n",
            "        [43, 50]]) (shape: torch.Size([2, 2]))\n",
            "\n",
            "Mat mul D (torch.Size([3, 2])) @ E (torch.Size([2, 3])):\n",
            "tensor([[ 27,  30,  33],\n",
            "        [ 61,  68,  75],\n",
            "        [ 95, 106, 117]]) (shape: torch.Size([3, 3]))\n",
            "\n",
            "========================================\n",
            "\n",
            "--- part 3: changing the shape and TRANSFERS ---\n",
            "Original shappe: torch.Size([3, 224, 224])\n",
            "After unsqueez: torch.Size([1, 3, 224, 224])\n",
            "\n",
            "Messy output shape: torch.Size([1, 10, 1])\n",
            "After squeese: torch.Size([10])\n",
            "\n",
            "Original TENSORS to flatten:\n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "totally FLATTENED:\n",
            "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]) (shape: torch.Size([12]))\n",
            "Flattened for linar:\n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]]) (shape: torch.Size([3, 4]))\n",
            "\n",
            "========================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "def part1():\n",
        "\n",
        "    print(\"--- part 1: TENSOR stuff  ---\")\n",
        "\n",
        "    # a single number\n",
        "    scalar = torch.tensor(42)\n",
        "    print(f\"SCALAR:\\n{scalar} (shape: {scalar.shape}, dim: {scalar.ndim})\")\n",
        "\n",
        "\n",
        "    # a list of numbers\n",
        "    vector = torch.tensor([1, 2, 3])\n",
        "    print(f\"vector:\\n{vector} (shape: {vector.shape}, dim: {vector.ndim})\")\n",
        "\n",
        "    # a table of numbers\n",
        "    matrix = torch.tensor([[5, 10],\n",
        "                           [15, 20]])\n",
        "    print(f\"mATRIx:\\n{matrix} (shape: {matrix.shape}, dim: {matrix.ndim})\")\n",
        "\n",
        "    # BIG data (like an image)\n",
        "    tensor_3d = torch.tensor([[[1, 2],\n",
        "                               [3, 4]]])\n",
        "    print(f\"3D tensor is just a:\\n{tensor_3d} (shape: {tensor_3d.shape}, dim: {tensor_3d.ndim})\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
        "\n",
        "\n",
        "def part2():\n",
        "    print(\"--- part 2: doing MATHS on tensors ---\")\n",
        "\n",
        "    # regular math\n",
        "    x = torch.tensor([1, 2, 3])\n",
        "\n",
        "    print(f\"Orig:\\n {x}\")\n",
        "    print(f\"Add 10: {x + 10}\")\n",
        "    print(f\"TIMES self: {x * x}\")\n",
        "\n",
        "    # matrix multiplication (MUST do this for NN's)\n",
        "    A = torch.tensor([[1, 2],\n",
        "                      [3, 4]])\n",
        "    B = torch.tensor([[5, 6],\n",
        "                      [7, 8]])\n",
        "\n",
        "    # (2, 2) times (2, 2) makes (2, 2)\n",
        "    C = torch.matmul(A, B)\n",
        "    print(f\"\\nMat mul A ({A.shape}) @ B ({B.shape}):\\n{C} (shape: {C.shape})\")\n",
        "\n",
        "\n",
        "\n",
        "    # this is how you FIX a SHAPE error\n",
        "    D = torch.tensor([[1, 2],\n",
        "                      [3, 4],\n",
        "                      [5, 6]])\n",
        "    E = torch.tensor([[7, 8, 9],\n",
        "                      [10, 11, 12]])\n",
        "\n",
        "    # D is (3, 2), E is (2, 3). inner are the same (2), so it works\n",
        "    F = torch.matmul(D, E)\n",
        "    print(f\"\\nMat mul D ({D.shape}) @ E ({E.shape}):\\n{F} (shape: {F.shape})\")\n",
        "    print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "def part3():\n",
        "    print(\"--- part 3: changing the shape and TRANSFERS ---\")\n",
        "\n",
        "    # add a dimension (used for adding a batch size of 1)\n",
        "    x = torch.rand(3, 224, 224) # just a rando image\n",
        "    print(f\"Original shappe: {x.shape}\")\n",
        "\n",
        "    # add a dimension at the start (dim=0)\n",
        "    x_batch = torch.unsqueeze(x, dim=0)\n",
        "    print(f\"After unsqueez: {x_batch.shape}\")\n",
        "\n",
        "\n",
        "    # remove dimensions of size 1 (clean up messy outputs)\n",
        "    z = torch.rand(1, 10, 1) # rando model output\n",
        "    print(f\"\\nMessy output shape: {z.shape}\")\n",
        "\n",
        "    z_clean = torch.squeeze(z)\n",
        "    print(f\"After squeese: {z_clean.shape}\")\n",
        "\n",
        "\n",
        "    # changing the shape (view) - important for LINEAR layers\n",
        "    tensor_to_flatten = torch.arange(12).reshape(3, 4)\n",
        "    print(f\"\\nOriginal TENSORS to flatten:\\n{tensor_to_flatten}\")\n",
        "\n",
        "    # -1 means 'figure out the size yourself'\n",
        "    flattened = tensor_to_flatten.view(-1)\n",
        "    print(f\"totally FLATTENED:\\n{flattened} (shape: {flattened.shape})\")\n",
        "\n",
        "    # keep 3 rows, but flatten the collums for the linear layr\n",
        "    flattened_linear = tensor_to_flatten.view(3, -1)\n",
        "    print(f\"Flattened for linar:\\n{flattened_linear} (shape: {flattened_linear.shape})\")\n",
        "    print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    part1()\n",
        "    part2()\n",
        "    part3()"
      ]
    }
  ]
}